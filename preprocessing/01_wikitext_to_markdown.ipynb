{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c5a8408b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import subprocess\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "90619106",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "INPUT_JSONL = \"data/tawiki_pages.jsonl\"\n",
    "OUTPUT_DIR = \"data/markdown_batches\"\n",
    "BATCH_SIZE = 1000   # pages per batch file\n",
    "# ---------------------------------------\n",
    "\n",
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d886d7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 12\n",
    "\n",
    "# Read index th entry from JSONL\n",
    "\n",
    "with open(INPUT_JSONL, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i == index:\n",
    "            page = json.loads(line)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f9d04068",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikitext = page['wikitext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e14aaf92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{{Infobox islands\\n| name             = இலங்கை\\n| image name       = \\n| image caption    = Map Sri Lanka\\n| image size       =\\n| locator map      = {{Location map|Indian Ocean|caption=|float=center|lat=7|long=81}}\\n| map caption      = Location of Sri Lanka in the Indian Ocean\\n| native name      = \\n| native name link = \\n| nickname         = Pearl of the Indian Ocean\\n| location         = [[இந்தியப் பெருங்கடல்]]\\n| coordinates      = {{coord|7|N|81|E|display=inline}}\\n| archipelago      =\\n| total islands    =\\n| major islands    =\\n| area_km2         = 65610\\n| rank             = 25th\\n| length_km        =\\n| width_km         =\\n| coastline_km     = 1340\\n| highest mount    = [[பிதுருதலாகலை]]\\n| elevation_m      = 2524.13\\n| country          = [[இலங்கை]]\\n| country admin divisions title     =\\n| country admin divisions           =\\n| country admin divisions title 1   =\\n| country admin divisions 1         =\\n| country admin divisions title 2   =\\n| country admin divisions 2         =\\n| country largest city              = [[கொழும்பு]]\\n| country largest city population   = 752,993\\n| population       = 20,277,597\\n| population as of = 2012\\n| density_km2      = 323\\n| ethnic groups    = [[சிங்களவர்]] – 75%,<br>[[இலங்கைத் தமிழர்]] – 11%,<br>[[இலங்கைச் சோனகர்]] 9%\\n| additional info  =\\n}}\\n[[படிமம்:Topography Sri Lanka.jpg|thumb|300px|right|இலங்கையின் புவியியல் அமைப்பு அல்லது நிலவமைப்புப் படம்]]\\n\\nஇலங்கை, இந்தியாவுக்குத் தெற்கே, இந்தியப் பெருங்கடலிலுள்ள ஒரு தீவு நாடாகும்.<ref name=\":0\">{{Cite web|date=May 11, 2021|title=Sri Lanka|url=https://www.cia.gov/the-world-factbook/countries/sri-lanka/|url-status=live|access-date=May 14, 2021|website=[[The World Factbook]]|publisher=[[Central Intelligence Agency]]|postscript=. {{PD-notice}}}}</ref><ref name=\"jc\">{{cite web|title=Joshua Calder\\'s World Island Info – Largest Islands of the World|url=http://www.worldislandinfo.com/LARGESTV1.html|url-status=live|access-date=2016-01-30|publisher=Worldislandinfo.com|postscript=.{{unreliable source|date=May 2021}}}}</ref><ref>{{Cite web |url=https://www.jpp.co.jp/lanka/geo/geote/geo05e.htm |access-date=2023-04-14 |website=www.jpp.co.jp}}</ref>\\n\\n{| class=\"toccolours\" border=\"1\" cellpadding=\"4\" style=\"float: right; margin: 0 0 1em 1em; width: 250px; border-collapse: collapse; font-size: 95%;padding:0.1em\"\\n|-\\n| colspan=\"2\" style=\"margin-left: inherit;background:#077cd0; color:white; font-size: 1.5em; text-align:center\" | \\'\\'\\'இலங்கை புவியியல்\\'\\'\\'\\n\\n|-\\n|\\'\\'\\'[[புவியியல்]] ஆள்கூறுகள்\\'\\'\\'\\n|7 00 வ, 81 00 கி\\n\\n|-\\n|\\'\\'\\'பரப்பளவு\\'\\'\\'\\n|65,610 ச.கி.மீ.\\n|-\\n|\\'\\'\\'நிலப்பரப்பளவு\\n|64,740 ச.கி.மீ.\\n|-\\n|நீர்ப்பரப்பளவு\\n|870 ச.கி.மீ.\\n|-\\n\\n|கரையோர நீளம்\\n|1,340 கி.மீ.\\n|-\\n\\n|நில எல்லைகள்\\n|0 கி.மீ.\\n|-\\n\\n|}\\n\\n== கடல்சார் உரிமைகள் ==\\nதொடர்ச்சியான பகுதியாக (contiguous zone) 24 [[கடல் மைல்]] தொலைவையும், கண்டமேடையாக 200 கடல் மைல் தூரத்தையும் கொண்டுள்ளது.\\n\\n\\'\\'\\'கடல்சார் உரிமைகள்:\\'\\'\\'\\n<br />\\'\\'தொடர்ச்சியான பகுதி:\\'\\'\\n24 கடல் மைல் (nm)\\n<br />\\'\\'[[கண்ட மேடை]]:\\'\\'\\n200 கடல் மைல் (nm)\\n<br />\\'\\'பிரத்தியேக [[பொருளாதாரம்|பொருளாதார]] வலயம்:\\'\\'\\n200&nbsp;nm\\n<br />\\'\\'பிரதேச கடல்:\\'\\'\\n12&nbsp;nm\\n\\n\\'\\'\\'[[காலநிலை]]:\\'\\'\\'\\ntropical பருவப் பெயர்ச்சிக் காற்று; வடகீழ்ப் பருவப் பெயர்ச்சிக் காற்று(டிசம்பரிலிருந்து மார்ச் வரை); தென்மேற் பருவப் பெயர்ச்சிக் காற்று(ஜூனிலிருந்து அக்டோபர் வரை)\\n\\n\\'\\'\\'நிலத்தோற்றம்:\\'\\'\\'\\nபெரும்பாலும் தாழ்வானது, தட்டை முதல் சிற்றளவான ஏற்ற இறக்கங்கள் கொண்டது; மலைகள் தெந் மத்திய பகுதியில்.\\n\\n\\'\\'\\'நிலைப்பட அந்தலைகள்:\\'\\'\\'\\n<br />\\'\\'மிகத் தாழ்ந்த புள்ளி:\\'\\'\\n[[இந்து சமுத்திரம்]] 0 m\\n<br />\\'\\'அதியுயர் புள்ளி:\\'\\'\\n[[பிதுருதலாகலை]] 2,524 m\\n\\n\\'\\'\\'இயற்கை வளங்கள்:\\'\\'\\'\\n[[சுண்ணாம்பு]]க் கல், [[காரீயம்]], கனிம மணல்கள், [[இரத்தினக்கல்|இரத்தினங்]]கள், பொஸ்பேற்றுகள், களி, நீர் [[மின்சாரம்]]\\n\\n\\'\\'\\'நிலப் பயன்பாடு:\\'\\'\\'\\n<br />\\'\\'பயிர்த்தொழில் செய்யத்தக்க நிலம்:\\'\\'\\n14%\\n<br />\\'\\'நிலையான [[பயிர்]]:\\'\\'\\n15%\\n<br />\\'\\'நிலையான [[புல்வெளி]]கள்:\\'\\'\\n7%\\n<br />\\'\\'[[காடு]]களும் மரச்செறிவுகளும்:\\'\\'\\n32%\\n<br />\\'\\'ஏனையவை:\\'\\'\\n32% (1993 கணக்கீடு)\\n\\n\\'\\'\\'[[நீர்ப்பாசனம்|நீர்ப்பாசன]]முள்ள நிலங்கள்:\\'\\'\\'\\n5,500 சது. கி.மீ.(1993 கணக்கீடு)\\n\\n\\'\\'\\'இயற்கை அழிவுகள்:\\'\\'\\'\\nஅவ்வப்போது தோன்றும் புயல்களும், சூறாவளிகளும்.\\n\\n\\'\\'\\'சூழல் - தற்காலச் சிக்கல்கள்:\\'\\'\\'\\n[[காடழிப்பு]]; [[மண்ணரிப்பு]]; சட்டவிரோத [[வேட்டை]]யினாலும், [[நகராக்கம்|நகராக்க]]த்தினாலும், [[காட்டுயிர்|வனவிலங்குகள்]] ஆபத்துக்குள்ளாகியிருத்தல்; அகழ்வு நடவடிக்கைகளினாலும், அதிகரித்துவரும் மாசடைதலாலும், கரையோர degradation; தொழிற்சாலைக் கழிவுகளாலும், கழிவு நீர் கலத்தலாலும், [[நன்நீர்]] வளங்கள் மாசடைதல்; கழிவு அகற்றல்; கொழும்பில் காற்று மாசடைதல்.\\n\\n\\'\\'\\'சுற்றுச்சூழல் - அனைத்துலக ஒப்பந்தங்கள்:\\'\\'\\'\\n<br />\\'\\'party to:\\'\\'\\nஉயிரினப் பன்வகைமை (Biodiversity), காலநிலை மாற்றம், பாலைவனமாதல், அழியும் நிலையிலுள்ள உயிரினங்கள், சுற்றுச் சூழல் மாற்றம், ஆபத்து விளைவிக்ககூடிய கழிவுகள், கடற் சட்டம், அணுவாயுத சோதனைத் தடை, ஓசோன் படலப் பாதுகாப்பு, கப்பல்கள் தொடர்பான மாசடைதல், ஈர நிலங்கள்.\\n<br />\\'\\'கையெழுத்திடப்பட்டது, ஆனால் ஏற்கப்படவில்லை:\\'\\'\\nகடல்வாழ் உயிரினப் பாதுகாப்பு\\n\\n== புவியியல் குறிப்புகள் ==\\n* முக்கிய இந்தியப் பெருங்கடல் கடற்பாதைக்கு அண்மையிலுள்ள அமைவிடம்.\\n* [[இந்து ஐதீகம்|இந்து தொல் நம்பிக்கைகளின்]]படி இராமபிரானால் கட்டப்பட்டதாகக் கருதப்படும் [[ஆதாம் பாலம்]] எனப்படும், இந்தியாவுடனான நிலத்தொடர்பு. இது தற்போது பெரும்பாலும் கடலுள் அமிழ்ந்தும் சில பகுதிகள் மட்டும் சங்கிலித் தொடர் போன்ற திட்டுகளாகக் [[கடல் மட்டம்|கடல் மட்ட]]த்துக்கு மேல் தெரியும் படியாகவும் அமைந்துள்ளது.\\n\\n== பின்வருவனவற்றையும் பார்க்கவும் ==\\n* [[இலங்கை ஆள்கூறு]]\\n* [[2000 இலங்கைச் சூறாவளி]]\\n\\n== உசாத்துணை ==\\n{{reflist}}\\n{{Commons category|Geography of Sri Lanka|position=right}}\\n\\n{{coord|7|00|N|81|00|E|type:country|display=title}}\\n{{Geography of Sri Lanka}}\\n\\n==மேற்கோள்கள்==\\n{{reflist}}\\n\\n[[பகுப்பு:இலங்கையின் புவியியல்| ]]'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikitext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "57c09f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def wikitext_to_markdown(wiki_text):\n",
    "    \"\"\"\n",
    "    Convert MediaWiki wikitext (including Tamil text) into Markdown format.\n",
    "    Strips templates, references, images, etc., and translates headings, lists,\n",
    "    bold/italic, and tables into Markdown syntax.\n",
    "    \"\"\"\n",
    "    text = wiki_text\n",
    "    \n",
    "    # 1. Remove HTML comments, <ref> references, and <nowiki> sections\n",
    "    text = re.sub(r'<!--.*?-->', '', text, flags=re.DOTALL)\n",
    "    text = re.sub(r'<ref[^>]*?>.*?</ref>', '', text, flags=re.DOTALL|re.IGNORECASE)\n",
    "    text = re.sub(r'<ref[^>]*/>', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'<nowiki>.*?</nowiki>', '', text, flags=re.DOTALL|re.IGNORECASE)\n",
    "    \n",
    "    # 2. Remove templates {{...}} (repeat in case of nested)\n",
    "    while True:\n",
    "        new_text = re.sub(r'\\{\\{[^{}]*\\}\\}', '', text)\n",
    "        if new_text == text:\n",
    "            break\n",
    "        text = new_text\n",
    "\n",
    "    # 3. Remove category tags\n",
    "    text = re.sub(r'\\[\\[Category:[^\\]]+\\]\\]', '', text)\n",
    "    \n",
    "    # 4. Remove images/files with all parameters - more aggressive approach\n",
    "    # MediaWiki image syntax: [[File:name.jpg|thumb|300px|right|caption]]\n",
    "    # Need to handle nested brackets properly\n",
    "    def remove_images(text):\n",
    "        # Match [[File: or [[Image: or [[:File: etc, and find the matching closing ]]\n",
    "        pattern = r'\\[\\[:?(?:File|Image|படிமம்|கோப்பு):[^\\[\\]]*(?:\\[[^\\[\\]]*\\][^\\[\\]]*)*\\]\\]'\n",
    "        return re.sub(pattern, '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Apply image removal multiple times to handle nested cases\n",
    "    for _ in range(3):\n",
    "        new_text = remove_images(text)\n",
    "        if new_text == text:\n",
    "            break\n",
    "        text = new_text\n",
    "    \n",
    "    # Remove leftover image parameter fragments\n",
    "    text = re.sub(r'\\b(?:thumb|thumbnail|frame|frameless|border|left|right|center|none|\\d+px)\\b\\|?', '', text)\n",
    "    \n",
    "    # Clean up leftover brackets, pipes, and parentheses from image removal\n",
    "    text = re.sub(r'\\]\\]\\s*$', '', text, flags=re.MULTILINE)  # trailing ]]\n",
    "    text = re.sub(r'^\\s*\\]\\]', '', text, flags=re.MULTILINE)  # leading ]]\n",
    "    text = re.sub(r'^\\s*\\)\\s*\\]\\]', '', text, flags=re.MULTILINE)  # ) ]] at line start\n",
    "    text = re.sub(r'\\|\\|+', '', text)  # multiple pipes\n",
    "    text = re.sub(r'\\(\\s*\\)', '', text)  # empty parentheses\n",
    "\n",
    "    # 5. Convert external links [http://url label] → label (or drop if no label)\n",
    "    def ext_link_repl(m):\n",
    "        return m.group(2) if m.group(2) else ''\n",
    "    text = re.sub(\n",
    "        r'\\[(?:https?://|ftp://)([^\\s\\]]+)(?:\\s+([^\\]]+))?\\]', \n",
    "        ext_link_repl, text\n",
    "    )\n",
    "    \n",
    "    # 6. Convert internal links [[Page|Label]] → Label or [[Page]] → Page\n",
    "    def int_link_repl(m):\n",
    "        page = m.group(1)\n",
    "        label = m.group(2)\n",
    "        # Skip namespace links like File: or Category:\n",
    "        if ':' in page:\n",
    "            prefix = page.lower().split(':', 1)[0]\n",
    "            if prefix in ('file', 'image', 'category', 'help', 'wikipedia', 'படிமம்', 'கோப்பு'):\n",
    "                return ''\n",
    "        return label if label else page\n",
    "    text = re.sub(\n",
    "        r'\\[\\[([^|\\]]+)(?:\\|([^]]+))?\\]\\]', \n",
    "        int_link_repl, text\n",
    "    )\n",
    "\n",
    "    # 7. Remove HTML/CSS attributes from tables (colspan, rowspan, style, etc.)\n",
    "    text = re.sub(r'\\s*(?:colspan|rowspan|style|class|align|valign|bgcolor|width|height)\\s*=\\s*\"[^\"]*\"', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\"\\s*(?:colspan|rowspan|style|class|align|valign|bgcolor|width|height)\\s*=\\s*'[^']*'\", '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # 8. Convert bold/italic markup per MediaWiki rules (BEFORE processing tables)\n",
    "    # Handle cases where bold markers might be misplaced\n",
    "    text = re.sub(r\"'''''(.*?)'''''\", r'***\\1***', text)  # bold+italic ''''' → ***\n",
    "    text = re.sub(r\"'''(.*?)'''\", r'**\\1**', text)        # bold ''' → **\n",
    "    text = re.sub(r\"''(.*?)''\", r'*\\1*', text)            # italic '' → *\n",
    "    \n",
    "    # Fix cases where ** ends up after text (from malformed wikitext like \"text:**\")\n",
    "    text = re.sub(r'([^*]):\\*\\*', r'**\\1:**', text)  # Move ** before colon\n",
    "    text = re.sub(r'([^*])\\*\\*:', r'**\\1:**', text)  # Ensure ** wraps properly\n",
    "    \n",
    "    # 9. Replace <br> with newline (for tables or paragraphs)\n",
    "    text = re.sub(r'<br\\s*/?>', '\\n', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # 10. Remove Wikipedia metadata sections (See also, References, External links, Categories)\n",
    "    # These sections typically appear at the end of articles\n",
    "    metadata_sections = [\n",
    "        r'==\\s*(?:இவற்றையும் பார்க்கவும்|See also|மேலும் காண்க)\\s*==.*',\n",
    "        r'==\\s*(?:மேற்கோள்கள்|References|குறிப்புகள்|சான்றுகள்)\\s*==.*',\n",
    "        r'==\\s*(?:வெளி இணைப்புகள்|External links|புற இணைப்புகள்)\\s*==.*',\n",
    "        r'==\\s*(?:நூற்பட்டியல்|Bibliography|நூல்கள்)\\s*==.*',\n",
    "        r'==\\s*(?:மேலும் படிக்க|Further reading)\\s*==.*',\n",
    "        r'\\[\\[பகுப்பு:.*?\\]\\]',  # Category tags in content\n",
    "        r'பகுப்பு:.*$',  # Category: lines\n",
    "    ]\n",
    "    \n",
    "    for pattern in metadata_sections:\n",
    "        text = re.sub(pattern, '', text, flags=re.DOTALL|re.MULTILINE|re.IGNORECASE)\n",
    "    \n",
    "    # 11. Final cleanup - remove extra spaces and normalize whitespace\n",
    "    text = re.sub(r'\\n\\s*\\n\\s*\\n+', '\\n\\n', text)  # max 2 consecutive newlines\n",
    "    text = re.sub(r'[ \\t]+', ' ', text)  # normalize spaces\n",
    "\n",
    "    # Now split into lines and process headings, lists, and tables\n",
    "    lines = text.splitlines()\n",
    "    result_lines = []\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        line = lines[i].strip()\n",
    "        \n",
    "        # Skip empty or whitespace-only lines that are just punctuation\n",
    "        if line and line in (']]', ')', ') ]]', '|', '||'):\n",
    "            i += 1\n",
    "            continue\n",
    "        \n",
    "        # A. Tables: collect lines from {| to |} and convert them\n",
    "        if line.startswith('{|'):\n",
    "            table_lines = [line]\n",
    "            i += 1\n",
    "            # Collect until end of table\n",
    "            while i < len(lines) and not lines[i].strip().startswith('|}'):\n",
    "                table_lines.append(lines[i].strip())\n",
    "                i += 1\n",
    "            if i < len(lines):\n",
    "                table_lines.append(lines[i].strip())  # include '|}'\n",
    "            # Convert the table block\n",
    "            md_table = convert_wikitable_to_markdown(table_lines)\n",
    "            result_lines.extend(md_table.splitlines())\n",
    "            i += 1\n",
    "            continue\n",
    "        \n",
    "        # B. Headings: e.g. == Heading == → \"## Heading\"\n",
    "        m = re.match(r'^(=+)\\s*(.*?)\\s*(=+)$', line)\n",
    "        if m and len(m.group(1)) == len(m.group(3)):\n",
    "            level = min(len(m.group(1)), 6)\n",
    "            heading_text = m.group(2).strip()\n",
    "            \n",
    "            # Skip metadata section headings if they somehow survived\n",
    "            skip_headings = [\n",
    "                'இவற்றையும் பார்க்கவும்', 'See also', 'மேலும் காண்க',\n",
    "                'மேற்கோள்கள்', 'References', 'குறிப்புகள்', 'சான்றுகள்',\n",
    "                'வெளி இணைப்புகள்', 'External links', 'புற இணைப்புகள்',\n",
    "                'நூற்பட்டியல்', 'Bibliography', 'நூல்கள்',\n",
    "                'மேலும் படிக்க', 'Further reading'\n",
    "            ]\n",
    "            if heading_text not in skip_headings:\n",
    "                result_lines.append('#' * level + ' ' + heading_text)\n",
    "            i += 1\n",
    "            continue\n",
    "        \n",
    "        # C. Horizontal rule: lines of ---- → ---\n",
    "        if re.match(r'^-+$', line):\n",
    "            result_lines.append('---')\n",
    "            i += 1\n",
    "            continue\n",
    "        \n",
    "        # D. Lists:\n",
    "        m_list = re.match(r'^([*#]+)\\s*(.*)', line)\n",
    "        if m_list:\n",
    "            markers, content = m_list.group(1), m_list.group(2).strip()\n",
    "            indent = '  ' * (len(markers) - 1)\n",
    "            if markers[0] == '*':\n",
    "                result_lines.append(f\"{indent}- {content}\")\n",
    "            else:  # markers[0] == '#'\n",
    "                result_lines.append(f\"{indent}1. {content}\")\n",
    "            i += 1\n",
    "            continue\n",
    "        \n",
    "        # E. Regular line (non-empty)\n",
    "        if line:\n",
    "            result_lines.append(line)\n",
    "        i += 1\n",
    "    \n",
    "    return \"\\n\".join(result_lines)\n",
    "\n",
    "def convert_wikitable_to_markdown(table_lines):\n",
    "    \"\"\"\n",
    "    Convert a list of lines in a MediaWiki table ({| ... |}) into Markdown table syntax.\n",
    "    \"\"\"\n",
    "    headers = []\n",
    "    rows = []\n",
    "    caption = None\n",
    "\n",
    "    # Check for caption (first line after \"{|\") that starts with \"|+\"\n",
    "    if len(table_lines) > 1 and table_lines[1].startswith('|+'):\n",
    "        caption = table_lines[1].lstrip('|+').strip()\n",
    "        table_lines.pop(1)\n",
    "    \n",
    "    # Join all lines and then re-split properly to handle multi-line cells\n",
    "    full_text = '\\n'.join(table_lines)\n",
    "    \n",
    "    # Remove HTML attributes from table cells (including colspan which we'll ignore)\n",
    "    full_text = re.sub(r'\\s*(?:colspan|rowspan|style|class|align|valign|bgcolor|width|height)\\s*=\\s*\"[^\"]*\"\\s*\\|', ' | ', full_text, flags=re.IGNORECASE)\n",
    "    full_text = re.sub(r'\\s*(?:colspan|rowspan|style|class|align|valign|bgcolor|width|height)\\s*=\\s*\"[^\"]*\"', '', full_text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Split by row separator |-\n",
    "    table_rows = re.split(r'\\n\\|-+\\n?', full_text)\n",
    "    \n",
    "    for row_text in table_rows:\n",
    "        row_text = row_text.strip()\n",
    "        if not row_text or row_text.startswith('{|') or row_text.startswith('|}'):\n",
    "            continue\n",
    "        \n",
    "        # Check if this is a header row (starts with !)\n",
    "        if row_text.startswith('!'):\n",
    "            # Split by !! for inline cells or \\n! for multi-line cells\n",
    "            cells = re.split(r'!!|\\n!', row_text)\n",
    "            cleaned_cells = []\n",
    "            for cell in cells:\n",
    "                cell = cell.lstrip('!').strip()\n",
    "                # Remove attributes after | in cell\n",
    "                if '|' in cell:\n",
    "                    cell = cell.split('|')[-1].strip()\n",
    "                if cell:\n",
    "                    # Convert bold/italic within cell\n",
    "                    cell = re.sub(r\"'''''(.*?)'''''\", r'***\\1***', cell)\n",
    "                    cell = re.sub(r\"'''(.*?)'''\", r'**\\1**', cell)\n",
    "                    cell = re.sub(r\"''(.*?)''\", r'*\\1*', cell)\n",
    "                    cleaned_cells.append(cell)\n",
    "            if not headers and cleaned_cells:\n",
    "                headers = cleaned_cells\n",
    "        \n",
    "        # Check if this is a data row (starts with |)\n",
    "        elif row_text.startswith('|'):\n",
    "            # Split by || for inline cells or \\n| for multi-line cells\n",
    "            cells = re.split(r'\\|\\||\\n\\|', row_text)\n",
    "            cleaned_cells = []\n",
    "            for cell in cells:\n",
    "                cell = cell.lstrip('|').strip()\n",
    "                # Remove attributes after | in cell (e.g., | content after removing attributes)\n",
    "                if '|' in cell:\n",
    "                    # Split and take last part (content after last |)\n",
    "                    cell = cell.split('|')[-1].strip()\n",
    "                if cell:\n",
    "                    # Convert bold/italic within cell\n",
    "                    cell = re.sub(r\"'''''(.*?)'''''\", r'***\\1***', cell)\n",
    "                    cell = re.sub(r\"'''(.*?)'''\", r'**\\1**', cell)\n",
    "                    cell = re.sub(r\"''(.*?)''\", r'*\\1*', cell)\n",
    "                    cleaned_cells.append(cell)\n",
    "            \n",
    "            # If only one cell and no headers yet, treat as caption\n",
    "            if len(cleaned_cells) == 1 and not headers and not rows:\n",
    "                caption = cleaned_cells[0]\n",
    "            elif cleaned_cells:\n",
    "                rows.append(cleaned_cells)\n",
    "    \n",
    "    # If no explicit header but rows exist, use first row as header\n",
    "    if not headers and rows:\n",
    "        headers = rows.pop(0)\n",
    "    if not headers:\n",
    "        return \"\"\n",
    "\n",
    "    # Determine the maximum number of columns\n",
    "    max_cols = max(len(headers), max((len(row) for row in rows), default=0))\n",
    "    \n",
    "    # Pad headers if needed\n",
    "    if len(headers) < max_cols:\n",
    "        headers += [''] * (max_cols - len(headers))\n",
    "\n",
    "    # Build markdown table\n",
    "    md = []\n",
    "    if caption:\n",
    "        md.append(f\"**{caption}**\\n\")  # Caption as bold heading\n",
    "    md.append(\"| \" + \" | \".join(headers) + \" |\")\n",
    "    md.append(\"| \" + \" | \".join(\"---\" for _ in headers) + \" |\")\n",
    "    for row in rows:\n",
    "        # Pad row if it has fewer cells than headers\n",
    "        if len(row) < len(headers):\n",
    "            row += [''] * (len(headers) - len(row))\n",
    "        # Truncate if too many cells\n",
    "        elif len(row) > len(headers):\n",
    "            row = row[:len(headers)]\n",
    "        md.append(\"| \" + \" | \".join(row) + \" |\")\n",
    "    md.append(\"\")  # blank line after table\n",
    "    return \"\\n\".join(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "782ab290",
   "metadata": {},
   "outputs": [],
   "source": [
    "md = wikitext_to_markdown(wikitext)\n",
    "md\n",
    "\n",
    "# save to test.md\n",
    "with open(\"test.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "79c68406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full table wikitext:\n",
      "{| class=\"toccolours\" border=\"1\" cellpadding=\"4\" style=\"float: right; margin: 0 0 1em 1em; width: 250px; border-collapse: collapse; font-size: 95%;padding:0.1em\"\n",
      "|-\n",
      "| colspan=\"2\" style=\"margin-left: inherit;background:#077cd0; color:white; font-size: 1.5em; text-align:center\" | '''இலங்கை புவியியல்'''\n",
      "\n",
      "|-\n",
      "|'''[[புவியியல்]] ஆள்கூறுகள்'''\n",
      "|7 00 வ, 81 00 கி\n",
      "\n",
      "|-\n",
      "|'''பரப்பளவு'''\n",
      "|65,610 ச.கி.மீ.\n",
      "|-\n",
      "|'''நிலப்பரப்பளவு\n",
      "|64,740 ச.கி.மீ.\n",
      "|-\n",
      "|நீர்ப்பரப்பளவு\n",
      "|870 ச.கி.மீ.\n",
      "|-\n",
      "\n",
      "|கரையோர நீளம்\n",
      "|1,340 கி.மீ.\n",
      "|-\n",
      "\n",
      "|நில எல்லைகள்\n",
      "|0 கி.மீ.\n",
      "|-\n",
      "\n",
      "|}\n"
     ]
    }
   ],
   "source": [
    "# Let's see the full table wikitext\n",
    "import re\n",
    "table_match = re.search(r'\\{\\|.*?\\|\\}', wikitext, re.DOTALL)\n",
    "if table_match:\n",
    "    print(\"Full table wikitext:\")\n",
    "    print(table_match.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b71fd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data/tawiki_pages.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5448it [00:02, 2113.64it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mINPUT_JSONL\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(INPUT_JSONL, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtitle\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen codecs>:319\u001b[39m, in \u001b[36mdecode\u001b[39m\u001b[34m(self, input, final)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Process all pages from JSONL and create parquet with text column\n",
    "data = []\n",
    "\n",
    "print(f\"Processing {INPUT_JSONL}...\")\n",
    "\n",
    "with open(INPUT_JSONL, 'r', encoding='utf-8') as f:\n",
    "    for line in tqdm(f):\n",
    "        record = json.loads(line)\n",
    "        title = record.get('title', '')\n",
    "        wikitext = record.get('wikitext', '')\n",
    "        \n",
    "        # Convert wikitext to markdown\n",
    "        markdown_content = wikitext_to_markdown(wikitext)\n",
    "        \n",
    "        # Format as markdown with title as heading\n",
    "        text = f\"# {title}\\n\\n{markdown_content}\"\n",
    "        \n",
    "        data.append({'text': text})\n",
    "\n",
    "# Create DataFrame and save as parquet\n",
    "df = pd.DataFrame(data)\n",
    "output_file = \"data/tawiki_markdown.parquet\"\n",
    "df.to_parquet(output_file, index=False)\n",
    "\n",
    "print(f\"\\nSaved {len(df)} pages to {output_file}\")\n",
    "print(f\"DataFrame shape: {df.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
